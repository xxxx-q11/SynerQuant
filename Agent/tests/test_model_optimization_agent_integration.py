"""
æ¨¡å‹ä¼˜åŒ– Agent é›†æˆæµ‹è¯• - ä½¿ç”¨çœŸå®çš„ LLM æœåŠ¡å’Œå®éªŒç»“æœ

æµ‹è¯• model_optimization_Agent.py çš„å®Œæ•´æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
1. çœŸå®çš„ LLM æœåŠ¡è°ƒç”¨
2. çœŸå®çš„ MCP å®¢æˆ·ç«¯äº¤äº’
3. çœŸå®çš„å®éªŒç»“æœå¤„ç†
"""
import sys
import json
import yaml
import os
import tempfile
from pathlib import Path
from unittest.mock import patch, MagicMock
import numpy as np
import pandas as pd

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))


def create_real_llm_service():
    """åˆ›å»ºçœŸå®çš„ LLM æœåŠ¡"""
    from Agent.agent_factory import create_agent
    
    # ä»ç¯å¢ƒå˜é‡è·å– API Keyï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼ˆéœ€è¦ç”¨æˆ·è®¾ç½®ï¼‰
    api_key = os.getenv("QWEN_API_KEY", "")
    if not api_key:
        print("âš ï¸  è­¦å‘Š: æœªè®¾ç½® QWEN_API_KEY ç¯å¢ƒå˜é‡ï¼Œå°†ä½¿ç”¨ Mock LLM")
        return None
    
    try:
        llm = create_agent(
            provider="qwen",
            api_key=api_key,
            model="qwen-turbo",  # æˆ– qwen-plus
            temperature=0.7
        )
        print(f"âœ… æˆåŠŸåˆ›å»ºçœŸå®çš„ LLM æœåŠ¡: {llm.get_provider()}")
        return llm
    except Exception as e:
        print(f"âŒ åˆ›å»º LLM æœåŠ¡å¤±è´¥: {e}")
        return None


def create_mock_pickle_file(file_path, data):
    """åˆ›å»ºæ¨¡æ‹Ÿçš„ pickle æ–‡ä»¶"""
    import pickle
    file_path = Path(file_path)
    file_path.parent.mkdir(parents=True, exist_ok=True)
    with open(file_path, 'wb') as f:
        pickle.dump(data, f)


def create_mock_mlflow_metric_file(file_path, value):
    """åˆ›å»ºæ¨¡æ‹Ÿçš„ MLflow æŒ‡æ ‡æ–‡ä»¶"""
    file_path = Path(file_path)
    file_path.parent.mkdir(parents=True, exist_ok=True)
    with open(file_path, 'w') as f:
        f.write(f"0 {value}\n")


def test_real_llm_optimization_suggestion():
    """æµ‹è¯•çœŸå®çš„ LLM ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
    print("=" * 80)
    print("æµ‹è¯• 1: çœŸå® LLM ç”Ÿæˆä¼˜åŒ–å»ºè®®")
    print("=" * 80)
    
    from Agent.model_optimization_Agent import ModelOptimizationAgent
    
    llm = create_real_llm_service()
    if not llm:
        print("âš ï¸  è·³è¿‡æµ‹è¯•ï¼šLLM æœåŠ¡ä¸å¯ç”¨")
        return
    
    agent = ModelOptimizationAgent(llm)
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„å½“å‰æŒ‡æ ‡
    current_metrics = {
        "ic_mean": 0.03,
        "ic_std": 0.02,
        "ir": 1.5,
        "rank_ic_mean": 0.025,
        "annualized_return": 0.10,
        "max_drawdown": -0.15
    }
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„ä¼˜åŒ–å†å²
    optimization_history = [
        {
            "iteration": 1,
            "metrics": {
                "ic_mean": 0.02,
                "annualized_return": 0.08,
                "max_drawdown": -0.18
            }
        }
    ]
    
    # è¯»å–æ¨¡æ¿é…ç½®
    with open(agent.template_path, 'r', encoding='utf-8') as f:
        current_config = yaml.safe_load(f)
    
    factors_count = 20
    
    print("ğŸ“Š å½“å‰æŒ‡æ ‡:")
    print(f"  - IC å‡å€¼: {current_metrics['ic_mean']:.4f}")
    print(f"  - å¹´åŒ–æ”¶ç›Š: {current_metrics['annualized_return']:.2%}")
    print(f"  - æœ€å¤§å›æ’¤: {current_metrics['max_drawdown']:.2%}")
    print()
    print("ğŸ¤– è°ƒç”¨çœŸå® LLM ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
    
    # è°ƒç”¨çœŸå®çš„ LLM
    suggestion = agent._llm_analyze_and_suggest(
        current_metrics=current_metrics,
        optimization_history=optimization_history,
        current_config=current_config,
        factors_count=factors_count
    )
    
    if suggestion:
        print("âœ… LLM è¿”å›äº†ä¼˜åŒ–å»ºè®®:")
        print(f"  - åˆ†æ: {suggestion.get('analysis', 'N/A')}")
        print(f"  - é—®é¢˜: {suggestion.get('issues', [])}")
        print(f"  - æ‘˜è¦: {suggestion.get('summary', 'N/A')}")
        print(f"  - å‚æ•°æ›´æ–°: {suggestion.get('model_params_update', {})}")
        print(f"  - ç†ç”±: {suggestion.get('reasoning', 'N/A')}")
        
        # éªŒè¯å»ºè®®æ ¼å¼
        assert 'model_params_update' in suggestion, "å»ºè®®åº”è¯¥åŒ…å« model_params_update"
        assert isinstance(suggestion['model_params_update'], dict), "model_params_update åº”è¯¥æ˜¯å­—å…¸"
    else:
        print("âš ï¸  LLM æœªè¿”å›å»ºè®®")
    
    print("âœ… çœŸå® LLM ä¼˜åŒ–å»ºè®®æµ‹è¯•å®Œæˆ")
    print()


def test_apply_real_llm_suggestion():
    """æµ‹è¯•åº”ç”¨çœŸå®çš„ LLM ä¼˜åŒ–å»ºè®®"""
    print("=" * 80)
    print("æµ‹è¯• 2: åº”ç”¨çœŸå® LLM ä¼˜åŒ–å»ºè®®")
    print("=" * 80)
    
    from Agent.model_optimization_Agent import ModelOptimizationAgent
    
    llm = create_real_llm_service()
    if not llm:
        print("âš ï¸  è·³è¿‡æµ‹è¯•ï¼šLLM æœåŠ¡ä¸å¯ç”¨")
        return
    
    agent = ModelOptimizationAgent(llm)
    
    # è¯»å–æ¨¡æ¿é…ç½®
    with open(agent.template_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # å…ˆè·å–çœŸå®çš„ LLM å»ºè®®
    current_metrics = {
        "ic_mean": 0.03,
        "ic_std": 0.02,
        "ir": 1.5,
        "rank_ic_mean": 0.025,
        "annualized_return": 0.10,
        "max_drawdown": -0.15
    }
    
    optimization_history = []
    factors_count = 20
    
    print("ğŸ¤– è·å– LLM ä¼˜åŒ–å»ºè®®...")
    suggestion = agent._llm_analyze_and_suggest(
        current_metrics=current_metrics,
        optimization_history=optimization_history,
        current_config=config,
        factors_count=factors_count
    )
    
    if not suggestion or 'model_params_update' not in suggestion:
        print("âš ï¸  æœªè·å–åˆ°æœ‰æ•ˆçš„ä¼˜åŒ–å»ºè®®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå»ºè®®")
        suggestion = {
            "model_params_update": {
                "lr": 0.0005,
                "n_epochs": 150,
                "d_model": 128
            }
        }
    
    print(f"ğŸ“ åº”ç”¨ä¼˜åŒ–å»ºè®®: {suggestion.get('model_params_update', {})}")
    
    # åº”ç”¨å»ºè®®
    updated_config = agent._apply_optimization_suggestion(config, suggestion)
    
    # éªŒè¯æ›´æ–°
    model_kwargs = updated_config['task']['model']['kwargs']
    original_kwargs = config['task']['model']['kwargs']
    
    print("\nğŸ“Š å‚æ•°å¯¹æ¯”:")
    for param, value in suggestion.get('model_params_update', {}).items():
        original_value = original_kwargs.get(param, "æœªè®¾ç½®")
        new_value = model_kwargs.get(param, "æœªè®¾ç½®")
        print(f"  - {param}: {original_value} -> {new_value}")
        assert model_kwargs.get(param) == value, f"å‚æ•° {param} åº”è¯¥è¢«æ›´æ–°ä¸º {value}"
    
    print("âœ… åº”ç”¨çœŸå® LLM ä¼˜åŒ–å»ºè®®æµ‹è¯•å®Œæˆ")
    print()


def test_full_optimization_flow_with_mock_results():
    """æµ‹è¯•å®Œæ•´çš„ä¼˜åŒ–æµç¨‹ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿçš„è®­ç»ƒç»“æœï¼‰"""
    print("=" * 80)
    print("æµ‹è¯• 3: å®Œæ•´ä¼˜åŒ–æµç¨‹ï¼ˆæ¨¡æ‹Ÿè®­ç»ƒç»“æœï¼‰")
    print("=" * 80)
    
    from Agent.model_optimization_Agent import ModelOptimizationAgent
    
    llm = create_real_llm_service()
    if not llm:
        print("âš ï¸  è·³è¿‡æµ‹è¯•ï¼šLLM æœåŠ¡ä¸å¯ç”¨")
        return
    
    # åˆ›å»ºæµ‹è¯•å› å­
    factors = [
        {"expression": "($close - $open) / $open", "ic": 0.05},
        {"expression": "($high - $low) / $close", "ic": 0.03},
        {"expression": "Mean($volume, 5) / $volume", "ic": 0.04}
    ]
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå­˜å‚¨ç»“æœ
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir = Path(tmpdir)
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„è®­ç»ƒç»“æœæ–‡ä»¶
        ic_data = pd.Series([0.05, 0.03, 0.04, 0.06, 0.02])
        ic_path = tmpdir / "ic.pkl"
        create_mock_pickle_file(ic_path, ic_data)
        
        rank_ic_data = pd.Series([0.04, 0.03, 0.05, 0.04, 0.03])
        rank_ic_path = tmpdir / "rank_ic.pkl"
        create_mock_pickle_file(rank_ic_path, rank_ic_data)
        
        annual_return_path = tmpdir / "annual_return.txt"
        create_mock_mlflow_metric_file(annual_return_path, 0.12)
        
        max_drawdown_path = tmpdir / "max_drawdown.txt"
        create_mock_mlflow_metric_file(max_drawdown_path, -0.14)
        
        # Mock MCP å®¢æˆ·ç«¯
        mock_mcp_client = MagicMock()
        mock_mcp_client.call_tool.return_value = json.dumps({
            "ic": str(ic_path),
            "rank_ic": str(rank_ic_path),
            "1day.excess_return_with_cost.annualized_return": str(annual_return_path),
            "1day.excess_return_with_cost.max_drawdown": str(max_drawdown_path)
        })
        
        agent = ModelOptimizationAgent(llm)
        agent.mcp_client = mock_mcp_client
        
        print(f"ğŸ“Š æµ‹è¯•å› å­æ•°é‡: {len(factors)}")
        print(f"ğŸ”„ æœ€å¤§è¿­ä»£æ¬¡æ•°: 2")
        print()
        
        # æ³¨æ„ï¼šè¿™é‡Œä¼šå°è¯•æ³¨å†Œå› å­æ± ï¼Œå¦‚æœ factor_pool_registry ä¸å¯ç”¨ä¼šå¤±è´¥
        # æ‰€ä»¥æˆ‘ä»¬åªæµ‹è¯•åˆ°é…ç½®ç”Ÿæˆéƒ¨åˆ†
        try:
            # æµ‹è¯•é…ç½®ç”Ÿæˆ
            factor_pool_name = "CustomFactors_Test"
            module_name = agent._to_snake_case(factor_pool_name)
            module_path = f"qlib_benchmark.factor_pools.{module_name}"
            
            yaml_config = agent._generate_initial_yaml_config(
                factor_pool_name=factor_pool_name,
                module_path=module_path,
                factors_count=len(factors)
            )
            
            print("âœ… é…ç½®ç”ŸæˆæˆåŠŸ")
            
            # æµ‹è¯•æŒ‡æ ‡æå–ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿç»“æœï¼‰
            train_result = {
                "ic": str(ic_path),
                "rank_ic": str(rank_ic_path),
                "1day.excess_return_with_cost.annualized_return": str(annual_return_path),
                "1day.excess_return_with_cost.max_drawdown": str(max_drawdown_path)
            }
            
            metrics = agent._extract_metrics(train_result)
            print(f"âœ… æŒ‡æ ‡æå–æˆåŠŸ:")
            print(f"  - IC å‡å€¼: {metrics.get('ic_mean', 'N/A')}")
            print(f"  - å¹´åŒ–æ”¶ç›Š: {metrics.get('annualized_return', 'N/A')}")
            
            # æµ‹è¯•å¾—åˆ†è®¡ç®—
            score = agent._compute_optimization_score(metrics)
            print(f"âœ… å¾—åˆ†è®¡ç®—: {score:.4f}")
            
        except Exception as e:
            print(f"âš ï¸  éƒ¨åˆ†åŠŸèƒ½æµ‹è¯•å¤±è´¥ï¼ˆå¯èƒ½æ˜¯ä¾èµ–é—®é¢˜ï¼‰: {e}")
            import traceback
            traceback.print_exc()
    
    print("âœ… å®Œæ•´ä¼˜åŒ–æµç¨‹æµ‹è¯•å®Œæˆ")
    print()


def test_real_mcp_integration():
    """æµ‹è¯•çœŸå®çš„ MCP å®¢æˆ·ç«¯é›†æˆï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
    print("=" * 80)
    print("æµ‹è¯• 4: çœŸå® MCP å®¢æˆ·ç«¯é›†æˆ")
    print("=" * 80)
    
    from Agent.model_optimization_Agent import ModelOptimizationAgent
    
    llm = create_real_llm_service()
    agent = ModelOptimizationAgent(llm)
    
    # æ£€æŸ¥ MCP å®¢æˆ·ç«¯æ˜¯å¦å¯ç”¨
    if not agent.mcp_client:
        print("âš ï¸  MCP å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè·³è¿‡æµ‹è¯•")
        print("   æç¤º: ç¡®ä¿ MCP æœåŠ¡å™¨è·¯å¾„æ­£ç¡®ä¸”å¯ç”¨")
        return
    
    try:
        # æµ‹è¯•åˆ—å‡ºå·¥å…·
        tools = agent.list_available_tools()
        print(f"âœ… æ‰¾åˆ° {len(tools)} ä¸ªå¯ç”¨å·¥å…·:")
        for tool in tools:
            print(f"  - {tool.get('name', 'Unknown')}: {tool.get('description', '')}")
        
        # æµ‹è¯•è°ƒç”¨å·¥å…·ï¼ˆä½¿ç”¨ä¸€ä¸ªç®€å•çš„æµ‹è¯•ï¼‰
        if tools:
            print("\nğŸ“‹ å·¥å…·åˆ—è¡¨è·å–æˆåŠŸ")
        else:
            print("\nâš ï¸  æœªæ‰¾åˆ°å¯ç”¨å·¥å…·")
            
    except Exception as e:
        print(f"âŒ MCP å®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print("âœ… çœŸå® MCP å®¢æˆ·ç«¯é›†æˆæµ‹è¯•å®Œæˆ")
    print()


def test_with_real_experiment_results():
    """ä½¿ç”¨çœŸå®çš„å®éªŒç»“æœè¿›è¡Œæµ‹è¯•"""
    print("=" * 80)
    print("æµ‹è¯• 5: ä½¿ç”¨çœŸå®å®éªŒç»“æœ")
    print("=" * 80)
    
    from Agent.model_optimization_Agent import ModelOptimizationAgent
    
    llm = create_real_llm_service()
    if not llm:
        print("âš ï¸  è·³è¿‡æµ‹è¯•ï¼šLLM æœåŠ¡ä¸å¯ç”¨")
        return
    
    agent = ModelOptimizationAgent(llm)
    
    # æŸ¥æ‰¾æœ€è¿‘çš„å®éªŒç»“æœç›®å½•
    mlruns_dir = Path("/data1/liuzhentao/trading_agent/mlruns")
    if not mlruns_dir.exists():
        print("âš ï¸  æœªæ‰¾åˆ°å®éªŒç»“æœç›®å½•ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    # æŸ¥æ‰¾æœ€æ–°çš„å®éªŒ
    experiment_dirs = [d for d in mlruns_dir.iterdir() if d.is_dir() and d.name.isdigit()]
    if not experiment_dirs:
        print("âš ï¸  æœªæ‰¾åˆ°å®éªŒç›®å½•ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    latest_experiment = max(experiment_dirs, key=lambda x: x.stat().st_mtime)
    print(f"ğŸ“ ä½¿ç”¨å®éªŒç›®å½•: {latest_experiment}")
    
    # æŸ¥æ‰¾æœ€æ–°çš„è¿è¡Œ
    run_dirs = [d for d in latest_experiment.iterdir() if d.is_dir()]
    if not run_dirs:
        print("âš ï¸  æœªæ‰¾åˆ°è¿è¡Œç›®å½•ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    latest_run = max(run_dirs, key=lambda x: x.stat().st_mtime)
    print(f"ğŸ“ ä½¿ç”¨è¿è¡Œç›®å½•: {latest_run}")
    
    # å°è¯•è¯»å–æŒ‡æ ‡æ–‡ä»¶
    metrics_dir = latest_run / "metrics"
    if metrics_dir.exists():
        metric_files = list(metrics_dir.glob("*.txt"))
        print(f"ğŸ“Š æ‰¾åˆ° {len(metric_files)} ä¸ªæŒ‡æ ‡æ–‡ä»¶")
        
        # æ„å»ºè®­ç»ƒç»“æœå­—å…¸
        train_result = {}
        for metric_file in metric_files:
            metric_name = metric_file.stem
            train_result[metric_name] = str(metric_file)
        
        # å°è¯•æå–æŒ‡æ ‡
        try:
            metrics = agent._extract_metrics(train_result)
            print("âœ… æˆåŠŸæå–æŒ‡æ ‡:")
            for key, value in metrics.items():
                if isinstance(value, (int, float)):
                    print(f"  - {key}: {value:.4f}" if isinstance(value, float) else f"  - {key}: {value}")
                else:
                    print(f"  - {key}: {value}")
        except Exception as e:
            print(f"âš ï¸  æŒ‡æ ‡æå–å¤±è´¥: {e}")
    else:
        print("âš ï¸  æœªæ‰¾åˆ° metrics ç›®å½•")
    
    print("âœ… çœŸå®å®éªŒç»“æœæµ‹è¯•å®Œæˆ")
    print()


def run_all_integration_tests():
    """è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•"""
    print("\n" + "=" * 80)
    print("å¼€å§‹è¿è¡Œæ¨¡å‹ä¼˜åŒ– Agent é›†æˆæµ‹è¯•å¥—ä»¶")
    print("=" * 80 + "\n")
    
    tests = [
        test_real_llm_optimization_suggestion,
        test_apply_real_llm_suggestion,
        test_full_optimization_flow_with_mock_results,
        test_real_mcp_integration,
        test_with_real_experiment_results,
    ]
    
    passed = 0
    failed = 0
    skipped = 0
    
    for test_func in tests:
        try:
            test_func()
            passed += 1
        except Exception as e:
            if "è·³è¿‡" in str(e) or "ä¸å¯ç”¨" in str(e):
                skipped += 1
                print(f"â­ï¸  {test_func.__name__} è¢«è·³è¿‡")
            else:
                failed += 1
                print(f"âŒ {test_func.__name__} å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        print()
    
    print("=" * 80)
    print(f"æµ‹è¯•å®Œæˆ: {passed} é€šè¿‡, {failed} å¤±è´¥, {skipped} è·³è¿‡")
    print("=" * 80)
    
    if failed > 0:
        print("\nğŸ’¡ æç¤º:")
        print("  - è®¾ç½® QWEN_API_KEY ç¯å¢ƒå˜é‡ä»¥ä½¿ç”¨çœŸå® LLM æœåŠ¡")
        print("  - ç¡®ä¿ MCP æœåŠ¡å™¨è·¯å¾„æ­£ç¡®")
        print("  - ç¡®ä¿å®éªŒç»“æœç›®å½•å­˜åœ¨")
    
    return failed == 0


if __name__ == "__main__":
    import os
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv("QWEN_API_KEY"):
        print("âš ï¸  è­¦å‘Š: æœªè®¾ç½® QWEN_API_KEY ç¯å¢ƒå˜é‡")
        print("   éƒ¨åˆ†æµ‹è¯•å°†ä½¿ç”¨ Mock æœåŠ¡æˆ–è·³è¿‡")
        print("   è®¾ç½®æ–¹æ³•: export QWEN_API_KEY='your-api-key'")
        print()
    
    success = run_all_integration_tests()
    sys.exit(0 if success else 1)

