"""Factor mining node"""
import os
from pathlib import Path
from typing import List
from state import AgentState
from utils.download import download_github_repo
from Agent.FactorMiningAgent import FactorMiningAgent


def factor_mining_node(state: AgentState) -> dict:
    """Factor mining node"""
    logs = ["[FactorMining] Executing factor mining"]
    factors = []
    selection_result = None
    
    try:
        llm_service = get_llm_service()
        agent = FactorMiningAgent(llm_service)
        
        # Get previous selection_result from state (if exists)
        previous_selection_result = state.get("selection_result", None)
        
        # Get mining feedback from state (for guiding this round of mining, generated by factor_eval)
        mining_feedback = state.get("mining_feedback", None)
        
        # If previous selection_result exists, it means returned from factor_eval
        if previous_selection_result:
            logs.append("[FactorMining] Detected previous operation record, will use different seed")
        
        # If mining feedback exists, print feedback information (new version fields)
        if mining_feedback:
            print("mining_feedback: ", mining_feedback)
            iteration = mining_feedback.get("iteration", 0)
            pool_weaknesses = mining_feedback.get("pool_weaknesses", [])
            suggested_directions = mining_feedback.get("suggested_directions", [])
            suggested_seeds = mining_feedback.get("suggested_seeds", [])
            gp_strategy_hints = mining_feedback.get("gp_strategy_hints", {})
            convergence_info = mining_feedback.get("convergence_info", {})
            
            logs.append(f"[FactorMining] Received iteration {iteration} feedback")
            logs.append(f"[FactorMining] Factor pool weaknesses: {len(pool_weaknesses)} items")
            logs.append(f"[FactorMining] Suggested directions: {len(suggested_directions)} items")
            logs.append(f"[FactorMining] LLM-suggested seed factors: {len(suggested_seeds)} items")
            
            # Print GP strategy suggestions
            if gp_strategy_hints:
                preferred_ops = gp_strategy_hints.get("preferred_operators", [])
                preferred_features = gp_strategy_hints.get("preferred_features", [])
                preferred_windows = gp_strategy_hints.get("preferred_windows", [])
                logs.append(f"[FactorMining] GP strategy - Recommended operators: {preferred_ops[:3]}...")
                logs.append(f"[FactorMining] GP strategy - Recommended features: {preferred_features[:3]}...")
                logs.append(f"[FactorMining] GP strategy - Recommended windows: {preferred_windows}")
            
            # Check if converged
            if convergence_info.get("is_converged", False):
                reason = convergence_info.get("convergence_reason", "Unknown")
                logs.append(f"[FactorMining] Warning: Convergence detection triggered - {reason}")
        
        # Call FactorMiningAgent, pass feedback information
        result, selection_result = agent.process(
            previous_selection_result=previous_selection_result,
            mining_feedback=mining_feedback
        )
        
        # result is a list, format: [{"expression": "factor_expression", "ic": IC_value}, ...]
        if isinstance(result, list):
            factors = result
            logs.append(f"[FactorMining] Successfully extracted {len(factors)} factors")
        else:
            logs.append(f"[FactorMining] Warning: Return result format incorrect, expected list, got {type(result)}")
            
    except Exception as e:
        error_msg = f"[FactorMining] Processing error: {str(e)}"
        logs.append(error_msg)
        print(f"Error: {error_msg}")
        import traceback
        traceback.print_exc()
    
    # Get existing sota_pool_list and origin_factor_pool_analysis_result from state, preserve them
    sota_pool_list = state.get("sota_pool_list", None)
    factor_pool_analysis_result_history = state.get("factor_pool_analysis_result_history", None)
    # Preserve mining_feedback state, pass to next round of factor_eval
    # Note: This preserves feedback generated by factor_eval, for iteration tracking
    mining_feedback_to_pass = state.get("mining_feedback", None)
    
    return {
        "factors": factors,
        "logs": logs,
        "current_node": "factor_mining",
        "sota_pool_list": sota_pool_list,
        "factor_pool_analysis_result_history": factor_pool_analysis_result_history,
        "selection_result": selection_result,
        "mining_feedback": mining_feedback_to_pass,
    }


def get_llm_service():
    """
    Get LLM service instance
    
    Returns:
        BaseAgent instance
    """
    from Agent.agent_factory import load_env_config, create_agent
    
    config = load_env_config()
    return create_agent(
        provider=config.get("provider", "qwen"),
        api_key=config.get("api_key"),
        model=config.get("model"),
        base_url=config.get("base_url"),
        temperature=config.get("temperature", 0.7),
        max_tokens=config.get("max_tokens"),
    )

