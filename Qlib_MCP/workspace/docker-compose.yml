# Docker Compose 配置文件
# 用于管理 Qlib_MCP 的各个 workspace 容器
version: "3.8"

services:
  # AlphaSAGE 训练服务 (GP/GFN/PPO 等算法)
  alphasage:
    image: alphasage-gp:latest
    container_name: alphasage-training
    build:
      context: ./workspace/AlphaSAGE
      dockerfile: Dockerfile
    volumes:
      # Qlib 数据挂载（只读）
      - ${QLIB_DATA_PATH:-~/.qlib/qlib_data}:/root/.qlib/qlib_data:ro
      # AlphaSAGE workspace 挂载（读写）
      - ./workspace/AlphaSAGE:/workspace
    environment:
      # Python 环境变量
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONPATH=/workspace:/workspace/src
      # CUDA 设备（可通过 .env 文件或命令行覆盖）
      - CUDA_VISIBLE_DEVICES=${CUDA_DEVICE:-0}
    working_dir: /workspace
    # GPU 资源配置
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${CUDA_DEVICE:-0}"]
              capabilities: [gpu]
    # 默认命令（可被 docker-compose run 覆盖）
    command: ["python3", "--version"]
    # 网络模式 - 使用 host 模式解决 MTU 不匹配问题（主机 bond0 MTU=1400，docker0 MTU=1500）
    network_mode: "host"
    # 标签（用于管理和识别）
    labels:
      com.qlib.mcp.workspace: "AlphaSAGE"
      com.qlib.mcp.type: "training"
    # 限制资源使用（可选）
    # mem_limit: 16g
    # cpus: 8

  # qlib_benchmark 基准测试服务 (XGBoost, LightGBM, GRU, MLP, KRNN, Linear 等)
  qlib-benchmark:
    image: qlib-benchmark:latest
    container_name: qlib-benchmark
    build:
      context: ./workspace/qlib_benchmark
      dockerfile: Dockerfile
    volumes:
      # Qlib 数据挂载（只读）
      - ${QLIB_DATA_PATH:-~/.qlib/qlib_data}:/root/.qlib/qlib_data:ro
      # qlib_benchmark workspace 挂载（读写）
      - ./workspace:/workspace
      #- ./workspace/qlib_benchmark:/workspace
      # Agent 目录挂载（用于 AgentEnhancedStrategy）
      - ../Agent:/workspace/Agent:ro
      # utils 目录挂载（Agent 依赖）
      - ../utils:/workspace/utils:ro
      # config 目录挂载（LLM 配置）
      - ../config:/workspace/config:ro
      - .:/workspace/Qlib_MCP:ro
      - ./workspace/news_data:/workspace/news_data:ro
    environment:
      # Python 环境变量
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      # 添加 Agent 到 PYTHONPATH
      - PYTHONPATH=/workspace:/workspace/Agent:${PYTHONPATH}
      # CUDA 设备（可通过 .env 文件或命令行覆盖）
      - CUDA_VISIBLE_DEVICES=${CUDA_DEVICE_BENCHMARK:-${CUDA_DEVICE:-0}}
    working_dir: /workspace
    shm_size: 2g
    # GPU 资源配置（如果需要 GPU 支持）
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${CUDA_DEVICE_BENCHMARK:-${CUDA_DEVICE:-0}}"]
              capabilities: [gpu]
    # 默认命令（可被 docker-compose run 覆盖）
    command: ["python3", "--version"]
    # 网络模式 - 使用 host 模式解决 MTU 不匹配问题（主机 bond0 MTU=1400，docker0 MTU=1500）
    network_mode: "host"
    # 标签（用于管理和识别）
    labels:
      com.qlib.mcp.workspace: "qlib_benchmark"
      com.qlib.mcp.type: "benchmark"
    # 限制资源使用（可选）
    # mem_limit: 16g
    # cpus: 8

# 未来可以添加更多 workspace 服务，例如：
#
#  alphasage-ppo:
#    image: alphasage-ppo:latest
#    build:
#      context: ./workspace/AlphaSAGE
#      dockerfile: Dockerfile
#    volumes:
#      - ${QLIB_DATA_PATH:-~/.qlib/qlib_data}:/root/.qlib/qlib_data:ro
#      - ./workspace/AlphaSAGE:/workspace
#    environment:
#      - PYTHONUNBUFFERED=1
#      - CUDA_VISIBLE_DEVICES=${CUDA_DEVICE:-0}
#    working_dir: /workspace
#    command: ["python3", "train_ppo.py"]
#
#  alphaforge:
#    image: alphaforge:latest
#    build:
#      context: ./workspace/AlphaForge
#      dockerfile: Dockerfile
#    volumes:
#      - ${QLIB_DATA_PATH:-~/.qlib/qlib_data}:/root/.qlib/qlib_data:ro
#      - ./workspace/AlphaForge:/workspace
#    environment:
#      - PYTHONUNBUFFERED=1
#      - CUDA_VISIBLE_DEVICES=${CUDA_DEVICE:-0}
#    working_dir: /workspace

